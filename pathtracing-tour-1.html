<meta charset="utf-8">
<link rel="stylesheet" href="style.css?">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<script>window.markdeepOptions = {tocStyle: 'short'};</script>
**PathTracing Tour - Our test scene**
				Anders Lindqvist - 2017-12-15 - [index](index.html) - [contact](https://twitter.com/anders_breakin)

tags: graphics

# Camera Rays

In computer graphics we traditionally create scenes with multiple meshes consisting of triangles. In order to generate an image of our scene we must shoot a ray through each pixel and into the scene to find the surface that is visible in that pixel. The *generate_camera_direction function* wants a pixel coordinate with x and y from 0.0 to 1.0. The full code we use looks like this:
~~~~~~~~~~~~
Float3 pathtrace_sample(...) {
 float cx = (x + uniform(thread_context)) * one_over_width;
 float cy = (y + uniform(thread_context)) * one_over_height;
 Float3 camera_direction = generate_camera_direction(camera, cx, cy);
 ...
~~~~~~~~~~~~
The function uniform returns a random number between 0.0 and 1.0. It uses thread_context to store the random seed such that multi-threading doesn't influence the random numbers. Using the camera position (*camera.position*) and the camera direction calculated here we have our ray. It starts at the camera and it travels in the direction of *camera_direction*. We can use *intersect_closest* to find out if we hit anything
~~~~~~~~~~~~
 ...
 IntersectResult i;
 if (intersect_closest(scene, camera.position, camera_direction, i)) {
  // hit, information in i
 } else {
  // miss
 }
 ...
~~~~~~~~~~~~

If we always wanted to shoot through the middle of the pixel we could have used
~~~~~~~~~~~~
float cx = (x + 0.5f) * one_over_width;
float cy = (y + 0.5f) * one_over_height;
Float3 camera_direction = generate_camera_direction(camera, cx, cy);
~~~~~~~~~~~~
instead.

# Diffuse Color

Armed with the ability to shoot rays into our scenes we now know something about the geometry of the scene. But we need more. What does the triangle look like? Is it metallic? Or plastic? Green? For each triangle we have a material that describe the surface properties for that triangle. Often a texture or a shader is used to give the surfaces varying surface properties over the triangles.

The surface properties are used as parameters to a material model. One of the simplest material models is called the Lambert model and that is what we are going to start with. In the Lambert model we have a single colored property called the diffuse color that describe how much light is reflected diffusively. If a surface with a bluish diffuse color is illuminate by a white light source it will reflect a bluish color. It is reflected over the entire hemisphere around the surface normal but more light is reflected in the direction of the surface normal.

Here is a diffuse only view of our test scene:

![Diffuse color of surfaces](images/pathtracing-tour/image1-1.png)

It was generated using the following code:

~~~~~~~~~~~~
Float3 pathtrace_sample(...) {
 float cx = (x + 0.5f) * one_over_width;
 float cy = (y + 0.5f) * one_over_height;
 Float3 camera_direction = generate_camera_direction(camera, cx, cy);

 IntersectResult i;
 if (intersect_closest(scene, camera.position, camera_direction, i)) {
  return i.diffuse;
 }
 return float3(0,0,0);
}
~~~~~~~~~~~~
It looks quite boring but hopefully it is the start of something.. less boring!

By evaluating *pathtrace_sample* multiple times for each pixel and each time using a different sampling position (selected by the two *uniform*-calls) we get anti-aliasing. We can see that the edges of objects are slightly fuzzy. This is because only a few samples within each pixel has been used. The fuzziness is what we later will call noise. The calling of *pathtrace_sample* is handled by the framework.

At this point in any graphics tutorial it most be noted that the scene should be entirely black since there are no light sources. So lets see our light sources:

# Lightsources

![Lightsources](images/pathtracing-tour/image1-2.png)

We have two types of light sources for now. The sky is acting as one big light. The other one is emissive materials. It looks a bit off having a sky without clouds and without a sun at the same time but lets keep it like that for now. The image was generated using the following code:
~~~~~~
Float3 pathtrace_sample(...) {
 float cx = (x + 0.5f) * one_over_width;
 float cy = (y + 0.5f) * one_over_height;
 Float3 camera_direction = generate_camera_direction(camera, cx, cy);

 IntersectResult i;
 if (!intersect_closest(scene, camera.position, camera_direction, i)) {
  return sky_color_in_direction(scene, camera_direction);
 }
 return i.emissive;
}
~~~~~~
With this I think we are ready to do start our little tour! See [next post](pathtracing-tour-2.html) here.

# Source code

* [post1.cpp](https://github.com/breakin/pathtracer/blob/master/post1/post1.cpp)
* [vector_math.h](https://github.com/breakin/pathtracer/blob/master/shared_code/vector_math.h)
* [shared.h](https://github.com/breakin/pathtracer/blob/master/shared_code/shared.h) / [shared.cpp](https://github.com/breakin/pathtracer/blob/master/shared_code/shared.cpp)
* [tour index](pathtracing-tour-0.html)

For questions or feedback please reach out to me at [twitter](https://twitter.com/anders_breakin)!

<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
